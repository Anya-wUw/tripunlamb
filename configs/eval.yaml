# @package _global_

defaults:
  - _self_
  - model: Llama-3.1-8B-Instruct #Llama-3.2-3B-Instruct #Llama-3.2-1B-Instruct
  - eval: popqa #tofu
  - paths: default
  - hydra: eval
  - experiment: null

model:
  model_args:
    device_map: cuda

mode: eval
task_name: ???
seed: 0

question_key: null
forget_split: null
retain_split: null
retain_logs_path: null
paths:
  output_dir: null